<script>
    import NextSection from "$lib/components/NextSection.svelte"
    import Waveform from "$lib/components/Waveform.svelte"
    import YouTube from "$lib/components/YouTube.svelte"
    import ImageMedia from "$lib/components/ImageMedia.svelte"
    import {metadata as m} from "../directory.svx"
    import X86 from '$lib/demos/reacoma/X86.svelte';
    import MaxwaveStart from '$lib/demos/reacoma/MaxwaveStart.svelte';
    import MaxwaveEnd from '$lib/demos/reacoma/MaxwaveEnd.svelte';
    import Sys from '$lib/demos/reacoma/Sys.svelte';

    const d = 250;
</script>

# ReaCoMa

[ReaCoMa Source Code](https://www.github.com/jamesb93/reacoma)

[ReaCoMa External Site](https://www.reacoma.xyz)

ReaCoMa is a collection of [Lua](http://www.lua.org/) scripts that facilitate using the [Fluid Corpus Manipulation](https://www.flucoma.org) (FluCoMa) first toolbox algorithms within the [REAPER digital audio workstation](https://www.reaper.fm). This suite of algorithms are designed to perform tasks such as signal decomposition, audio descriptor analysis and segmentation. The main motivation of ReaCoMa was to consolidate my compositional workflow within REAPER and to extend that environment rather than having to switch between various pieces of software such as Max. Prior to ReaCoMa's existence there was no way of directly using FluCoMa's tools within REAPER. There were Max externals available, but for me, having to alternate between two distinct pieces of software, with vastly different interfaces and setups is a suboptimal compositional workflow. For example, processing audio files in Max and accessing the results within REAPER requires outputting those results to disk and making them a part of the REAPER session. This workflow is potentially time consuming if there are lots of audio files and requires several stages of manual file management. An ideal workflow would be to instead perform that processing within REAPER directly on media items. ReaCoMa functions exactly in this way and makes FluCoMa's first toolbox algorithms feel like a first class citizen in REAPER and enables possibilities within that environment for sound design and composition that are otherwise not readily available. From ReaCoMa's nascent stages of development I liberally used it for processing sound materials in [Reconstruction Error]({m.re}). Since then it has found its place as a fixture of my practice and a key tool for processing, manipulating and organising sounds such as in [{m.emname}]({m.em}).

ReaCoMa matured over a number of iterations as I incorporated into my compositional practice. Nonetheless, even it its earliest versions it facilitated computer-led decomposition of sounds which had a large impact on how I composed the works and structured my engagement with audio-based corpora.


In sys.ji_ from [Reconstruction Error]({m.re}) the `fluid.transients.lua` script is used to decompose a longer passage of material into a transient component and a residual component (everything except the transients). A long fade in envelope is applied to the residual component and both components are played back at the same time. This gradually introduces the residual parts of the sound while the transients dominate from the outset. I chose this effect as a way of generating various colours of short click-like sounds and as a way of suppressing the noisier aspects of the sound temporarily and to create a formal shape from this.

1:18 - 2:00
<Sys />

---

In dotmaxwave, `fluid.hpss.lua` is used to separate the harmonic component of a sound from the percussive component. This is applied to some source material with a very dominant pitch content and a subtle amount of noise.  With this separation I achieved a level of control over shaping the sound that is otherwise difficult without such decomposition techniques. It also guided me towards structuring the piece as an exhibition of the two components antagonising each other in different capacities.

1:14 - 2:00 i strip away the noise component leaving only the most harmonic parts. Creates a kind of purity in the sound world momentarily

<MaxwaveStart />

3:07 to 3:37 i accentuate the noise entirely and over-compress in order to flatten the dynamics of the sound into a more static texture.

<MaxwaveEnd/>



In X86.Desc.a, a section spanning 1:20 to 1:37 is built from from several interlocking streams of impulse-based materials or clicks. These were not manually created in an intuitive way or generated by the computer, rather, they were discovered by extracting the transients from an noise-based source material that I encountered through other computer-aided processes. With this approach, I was able to find intricate and varied patterns of this type of material by exploring with decomposition processes.  This is demonstrated in [DEMO 4]({m.reacoma}#demo4).

<X86 title="DEMO 4" id="demo4"/>

## Implementation
There is not a native [REAPER extension](https://www.reaper.fm/sdk/plugin/plugin.php) or audio plug-in that allows composers to use the FluCoMa first toolbox algorithms directly within the REAPER environment. As such, ReaCoMa is designed as a scripting bridge between the command line executables and the REAPER session where media items are positioned, selected and manipulated on a timeline. Thus, ReaCoMa offers a suite of scripts, where each script is responsible for implementing a single algorithm. For example, `fluid-hpss.lua` is used to execute the `fluid.hpss` algorithm, the same as what is found in Max as the object `fluid.hpss~`. To start, the user runs one of the Lua scripts while a media item or group of items are selected.

<ImageMedia>
    <img alt="step 1" 
    src="/tech-reacoma/step1.jpg" 
    slot="media">
    <p slot="caption">
        The user interface for parameter selection is shown after selecting and running one of the Lua scripts.
    </p>
</ImageMedia>

Once the user has configured the parameters they can execute the algorithm by clicking the "Okay" button. Depending on the type of algorithm an update will be made to the REAPER session. In this case, `fluid.hpss` returns two new takes and appends it to the source media item. One take will contain the harmonic component while the other take will contain the percussive component. This facilitates rapid auditioning of the decomposition results by toggling which take is active and playing back the session. I have found this procedure particularly useful in my compositional process as the source material is always stored and attached to the decomposition process, allowing me to follow the development of sonic materials directly in the session.

<ImageMedia>
    <img 
    alt="step 2" 
    src="/tech-reacoma/step2.jpg"  
    slot="media"
    >
    <p slot="caption">
        Takes containing the harmonic and percussive components are appended to the source media item.
    </p>
</ImageMedia>

For the segmentation algorithms (fluid.onsetslice, fluid.noveltyslice, fluid.ampslice, fluid.ampgate, fluid.transientslice) the original source media item is divided at the slice time points returned by the algorithm. This does not create new audio files on disk, rather, it creates new takes with the original source audio file and adjusts the start and length of those takes. Below the file is segmented with `fluid-noveltyslice.lua`.

<ImageMedia>
    <img alt="step 3" 
    src="/tech-reacoma/step3.jpg" 
    slot="media">
    <p slot="caption">
        fluid-noveltyslice.lua is applied with default parameters, rendering new takes at each slice time point.
    </p>
</ImageMedia>

## Experimental Scripts

The main goal of ReaCoMa was to implement scripts where the first toolbox algorithms could be incorporated into a REAPER session where audio files are manipulated, positioned and processed. Achieving this required significant research to understand the ReaScript API. New possibilities became apparent in this research, such as attaching additional metadata to items through notes, organising media items according to audio descriptor data and enhancing the segmentation workflow through automatic parameter selection. From this, three categories of experimental scripts emerged.

### Sorters
<!-- LINK: link to anchors piece in Interferences. You used it to organise sounds in this piece. -->
These scripts sort media items in the REAPER session timeline by ordering them according to audio descriptor analysis. There are two variants, one that sorts by spectral centroid and one that sorts by loudness. To produce a descriptor for each media item it performs a frame-by-frame analysis and then averages the per-frame values. Each segment is then sorted along the timeline according to this summary. Below is a recording of experimentation with slide and electric guitar that was made for [Refracted Touch]({m.rt}). This recording can be segmented using `fluid-amp.lua` which divides the source into several samples. By running `sort-by-loudness.lua`, the quietest segmented sections are shifted earlier in time and the loudest later in a contiguous arrangement. I have found this useful for selecting materials based on descriptors, or for constructing short phrases where the arrangement of materials according to descriptor values is desired.

### Auto-Slicing
Performing segmentation with the computerÂ often requires the user to specify a series of parameters such as the sensitivity of a threshold. Sometimes this process is not intuitive or it can be difficult to find a combination of parameters that achieves the desired segmentation. The goal of the 'auto-slicing' scripts is to automatically find the optimal settings for the `fluid.noveltyslice` algorithm so that it produces a fixed amount of slices. It solves this problem iteratively through brute force, incrementally adjusting how far it tunes the parameter at each iteration as it gets closer to the result. The main downside of the 'auto-slicing' scripts is that they only find a solution by changing a single parameter and leaving the others fixed. Another approach could use a neural network to discover combinations of changes effect the output. This would allow the process of automatic parameter finding to take into account the coupled nature of the parameters.

<ImageMedia>
    <img alt="auto slicing" 
    src="/tech-reacoma/autoslice.jpg" 
    slot="media">
    <p slot="caption">
        10 slices are found for this sound file by automatically tuning the 'threshold' parameter of fluid.novetlyslice.
    </p>
</ImageMedia>

### Tagging
For mixing I wanted to be able to annotate media items with descriptor analysis data. The tagging scripts, `tag-centroid.lua`, `tag-loudness.lua` and `tag-pitch.lua`, use the relevant descriptor algorithm from the toolbox (fluid.spectralcentroid, fluid.loudness, fluid pitch) to calculate statistics (average, minimum, maximum, median) of that audio descriptor across all the frames or values of a media item. This analysis is appended as a note to the media item and can be quickly viewed by hovering over the note icon. Instead of having to alternate between REAPER and another environment, I could make quick assumptions about the perceived loudness, brightness or pitch of samples to inform decisions involved in selecting sounds or their organisation.

<ImageMedia>
    <img alt="tagging" 
    src="/tech-reacoma/tagging.jpg" 
    slot="media">
    <p slot="caption">
        Each item has been tagging using tag-loudness.lua. The results can be quickly viewed by hovering over the note.
    </p>
</ImageMedia>

## Other Links
I produced a series of video tutorials that demonstrate how to install and use ReaCoMa. This video series is useful as a resource that documents how the user facing parts of ReaCoMa work and demonstrate some use cases outside my own practice.

<div class="video-grid"> 
<YouTube title="ReaCoMa Tutorial 1" url="https://www.youtube.com/embed/r3uHMXmlPRo" height={d} width={d}/>
<YouTube title="ReaComa Tutorial 2" url="https://www.youtube.com/embed/ejQu06GDDXE" height={d} width={d}/>
<YouTube title="ReaCoMa Tutorial 3" url="https://www.youtube.com/embed/HcF_lssW2Tg" height={d} width={d}/>
<YouTube title="ReaCoMa Tutorial 4" url="https://www.youtube.com/embed/og_5hCm5AGc" height={d} width={d}/>
<YouTube title="ReaCoMa Tutorial 5" url="https://www.youtube.com/embed/8__dtafBTD4" height={d} width={d}/>
<YouTube title="ReaCoMa Tutorial 6" url="https://www.youtube.com/embed/GEyut6MePgY" height={d} width={d}/>
</div>

<NextSection 
next="Finding Things in Stuff"
link={m.ftis}
/>

<style>
    .video-grid {
        display: grid;
        grid-template-columns: 50% 50%;
    }
</style>