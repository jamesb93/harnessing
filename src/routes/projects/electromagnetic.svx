<script>
	import NextSection from "$lib/components/NextSection.svelte"
    import {metadata as m} from "../directory.svx"
    import VideoMedia from '$lib/components/VideoMedia.svelte';
    import VideoMedia2 from '$lib/components/VideoMedia2.svelte';
    import ImageMedia2 from '$lib/components/ImageMedia2.svelte';
    import YouTube from '$lib/components/YouTube.svelte';
    import Album from '$lib/components/Album.svelte';
    import Code from '$lib/components/Code.svelte';
    import Waveform from '$lib/components/Waveform.svelte'; 

    import { 
        interAlbum, 
        kindleModes, 
        xiaomiModes 
    } from '$lib/data/interferences.js';
</script>

# Interferences

<Album
tracks={interAlbum}
title="Interferences"
id='audio1'
figure='AUDIO 1'
/>

Interferences is the fifth and final project in this portfolio. It is a pair of two medium length works presented as an EP. There is a git repository which contains all of the Python code and Max patches which were used. This can be found at: https://github.com/jamesb93/interferences

## Motivations and Influences
A major motivation in this project was to develop the workflow I had established in [Reconstruction Error]({m.re}) and to build on my creative coding practice with Python, Max, REAPER and [FTIS]({m.ftis}). There were two aspects to this motivation. Firstly, I wanted to recreate the experience of navigating through a corpus of unknown materials led by the computer through *structured listening* as I had done in [Reconstruction Error]({m.re}). Although I only utilised a small portion of the databending corpus, I wanted to generate a new corpus with its own origins, whilst still situating my work within a digital and synthetic aesthetic. At the time, I had been interested in [circuit bending](https://en.wikipedia.org/wiki/Circuit_bending) and the vast number of sounds that breaking apart and reconstructing old electronics could generate. The aesthetic of these sounds suits my sensibilities well, and I imagined that collecting a number of them could be a path forward to creating the corpus that I would need for composition. Tangential to this research, I came across a video of Nicolas Collins using an induction microphone to amplify the sounds of electromagnetic interferences generated by everyday appliances and objects. This video can be seen in [VIDEO 1]({m.em}#vid1). It struck me that instead of circuit bending, this might be a suitable technique for creating a corpus with the properties I desired. Following this hunch I obtained an [Elektrosluch Mini induction microphone](https://store.lom.audio/products/elektrosluch-mini-city-diy-kit-1?variant=4542176460832) capable of recording electromagnetic waves. I describe how this device was instrumental in the compositional process further in ["Recording Objects With Transduction"]({m.em}#recording-objects-with-transduction).

<YouTube 
url="https://www.youtube.com/embed/4T7qkYY7LZM"
caption='Nicolas Collins demonstrating induction to record electromagnetic fields generated by everyday electrical appliances.'
figure='VIDEO 1'
id='vid1'
/>

Secondly, I wanted to iterate on using the connected process of segmentation, analysis, dimension reduction and clustering and apply it more fluidly to compositional materials. The technology implemented in [Reconstruction Error]({m.re}) was very successful to me creatively, but was largely inflexbile and to perform the same tasks on new material would require rewriting the scripts. Throughout this project, [FTIS]({m.ftis}) supported this venture, and made it possible create  scripts that supported experimentation and data manipulation. This aspect is discussed in more detail in ["Pathways Through The Corpus"]({m.em}#pathways-through-the-corpus).


## Composition Process

The composition process can roughly be divided into  two phases of composition. The first phase involved a lot of experimentation with [FTIS]({m.ftis}) implementing various ways navigating through the corpus using machine learning and listening.  In the second phase, two pieces emerged out of these experiments and instead of using the computer to explore more broadly, I used it to search for and hone in on specific materials within the corpus of electromagnetic sounds. 

### Recording Objects With Induction
As discussed in ["Motivations And Influences"]({m.em}#motivations-and-influences), I procured an electromagnetic induction microphone and wanted to use it to generate a corpus of digital and synthetic type sounds. To do this, I took electronic objects from around the home and recorded them, at times while operating them simultaneously. I was surprised by the diversity of sounds this produced. Despite the devices seeming dormant, the induction recording technique could detect and uncover their invisible mechanisms and operation. I recorded a number of devices, including my computer keyboard, mouse, a mobile phone, a sound card, a laptop and an e-reader. Each device produced its own characteristic sounds - and some of these objects offered me the ability to trigger certain sonic behaviours. For example, [AUDIO 2]({m.em}#aud2) captures the sound of the e-reader in a dormant state. The change at 0:02 is triggered by switching the aeroplane mode on or off. This user interaction causes the components in the e-reader to operate differently, which is captured by the induction microphone. Eventually the initial static state is returned to. This can be heard at 1:59 lasting until the end of the clip.

<Waveform 
file='/inter/kindle-gesture.mp3'
peaks='/inter/kindle-gesture.dat'
id='aud2'
title='Induction recording of e-reader while switching the aeroplane mode on and off'
caption='AUDIO 2'
segments={kindleModes}
/>

Other objects produced their own characteristic material, but to my interpretation would always possess some kind of distinction between *active* and *passive* states.  For example, [AUDIO 3]({m.em}#aud3) is an induction recording taken from a mobile phone. I left the microphone to record this device for some time. In my interpretation this recording can be divided into these two classes, where 0:00 to 0:40 is static, and the remainder of the recording is passive.

<Waveform
file='/inter/xiaomi-gesture.mp3'
peaks='/inter/xiaomi-gesture.dat'
id='aud3'
title='Induction recording of mobile phone without user interaction'
caption='AUDIO 3'
segments={xiaomiModes}
/>

Across several of the samples I heard this presentation of two different types of material. It resonated with other works I knew and I started to build a sound world in my head for how these electromagnetic recordings might be drawn into composition. Thinking in terms of activity. This relates to other listening influences

<!-- - Alvin Lucier
- https://www.youtube.com/watch?v=4T7qkYY7LZM&list=PLyFW-rnLqSeGxwsL0FL160g8y6XmdHZcQ
- Jay-Dea Lopez
- Bernhard Gunter - A little bit of dirty snow
-->

I found 

Relationship to musical sounds.


### Static Versus Gestural Material
- Examples

- ClusterFck

### Segmentation
- Clustered Segmentation
    - Oversegmenting the sound andusing clustering to combine adjacent clusters that are similar
        - Gives the process a kind of "lookahead" because the differences across the entire window of analysis contribute to the clustering behaviour.
        - Thus, avoids the problem of trying to find the perfect threshold, and off-loads that to a process well suited to the conceptual and practical goal.
    - Similar work https://hal.archives-ouvertes.fr/hal-00512744/document
        - This gave me a good separation, although revealed as well how much of the material was relatively,e specially among the static classification.


### Pathways Through The Corpus
- HDBSCluster Exploration
    - Mechanised nature produced by looping, while still maintaining a sense that it could have been generated from machinery or by electromagnetic interference.
    - Cluster 37 note??
    - Cluster 18 (quiet sounds)
    - Cluster 33
- Sorting by quietness
    - Using FTIS's corpus filtering to create pockets of material
    - Don't have to deal with a whole corpus, start with a subsection and then operate on that. very powerful and flexible compared to 

- REAPER exporting and "sketching"
    - idea2-loops-iteration.RPP


### Mixing Sounds From [Reconstruction Error]({m.re})

- This demonstrated the expressive power of FTIS, in that I could rapidly combine corpora and begin making connections between different parts of my pratice. (Quietest.RPP for example)

06/08/2020 16:36:09

There seems to be some solid material interests emerging now. 

1. Iterated sounds that have some kind of rhythmic qualitiy to them
2. Time stretched textures that might have a noisy quality to them
3. Rapidly changing micro gesture


## Compositions
### EEE (placeholder)
- Focus on disintegrating the kindle sample and finding connections to the disintegrated parts
- 
### Anchors (placeholder)
convolution_three_anchors.py

https://github.com/jamesb93/interferences/blob/0773d279b98925cfa7a8b4008ab901d19af5c45b/MultiCorpus/scripts/convolution_three_anchors.py

For this particular track 'anchors', I want the form to almost feel shapeless in the long term. I don't want it to feel like its necessarily pushing toward a climatic point, rather that the music exists in a holding pattern and has ebbs and flows of material within that pattern. This is also part of making the material work musically, I have a quasi-conceptual idea of the sounds being reconstructed into the machines from which they were extracted. Part of frustrations in databending was the fact that the forms felt quite similar because I was focusing on stringing together various meso-form ideas without much consideration for how they would exist as a long term structure. By the time I got to the natural conclusion of each piece's materials in the composition process I had already crystallised a structure that wasn't that malleable.

## Reflection


Aestheticise the unheard and procedural sounds of technology. Kindle on/off thing.

Mouse-2.wav sample becoming a pitched motif.
Xiaomi sample in Anchors
The way that my listening is structured through technology leads me to these kinds of concepts.



### Using the computer to work from more knowns in composition
- The electromagnetic stuff creates a foundation, a base from which I created material links elsewhere and drew into single compositions.
### Towards a stable workflow

Would have I been able to segment the material at the scale it existed at, analyse it and do the other various processes without the computer?

<NextSection 
next="Technical Implementation and Software"
link={m.ti}
/>
    