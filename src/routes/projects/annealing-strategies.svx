<script>
	import NextSection from "$lib/components/NextSection.svelte";
    import {metadata as m} from "../directory.svx";
    import VideoMedia from "$lib/components/VideoMedia.svelte";
    import ImageMedia from "$lib/components/ImageMedia.svelte";
    import YouTube from "$lib/components/YouTube.svelte";
    import Caption from "$lib/components/Caption.svelte";
    import Waveform from "$lib/components/Waveform.svelte";

    import { segs4 } from "$lib/components/data/as.js";
</script>

# Annealing Strategies
Annealing Strategies is a piece that is created by a content-aware program. It uses an audio descriptor to measure the perceptual loudness of a "Fourses" synthesiser alongside "Simulated Annealing" (SA), an optimisation technique that over time discovers what combination of complex coupled parameters for the synthesiser create the quietest possible output. Iterations of this work were created en-masse and through curation of those outputs and fine tuning of the SA algorithm I arrived at a final rendition of the work.

## Motivations and Influences

The initial inspiration for this piece emerged when I came across a digital implementation of a "Fourses" synthesisers on the [cycling 74](https://cycling74.com/forums/recreating-a-horsefourses-oscillator/)> forums. I had never come across this particular synthesiser before, and there were two aspects that made me inquisitive and wanting to use this synth for *something* creative without any specific ideas for what that project would be. Firstly, experimenting with the [collectively designed Max patch](https://cycling74.com/forums/recreating-a-horsefourses-oscillator/replies/1#reply-58ed2132c2991221d9cc767c) demonstrated the range of sounds it could produce, including noisy, pitched, harmonic and inharmonic timbres. In particular the quietest sounds interested me as they were novel and hard to discover amongst numerous loud sounds. Furthermore, the quieter states were unstable in nature and would sometimes produce localised morphological variation. Secondly, listening to the synthesiser and interacting with its 24 parameters inspired a technological question about how a computer might be able to *find* parameter combinations that would result in specific perceptual outputs. From this idea I imagined a piece where the synthesiser is seeded in an untamed and loud state and the computer, in real-time explores combinations of parameters to gradually reach a quiet state. This process would shape the structure of the piece and the journey from the starting point to the "solution" would impose a structure on that process.

As I researched around these interests, I came across Stefano Fasciani, who in his work has researched the development of new perceptually grounded interfaces for synthesisers. In "TSAM: A Tool for Analyzing, Modelling And Mapping The Timbre Of Sound Synthesizers" Fasciani (2016) describes a program that uses audio descriptors and neural networks to "enable the study of how changes to a synthesis parameter affect timbral descriptors". This creates the possibility for real-time interaction with a synthesiser by navigating through a visual space that distributes timbral possibilities spatially rather than interfacing with the individual parameters. In VIDEO 1, Fasciani demonstrates how this works by using TSAM to analyse many combinations of parameters and the sound it produces.

<YouTube 
url="https://www.youtube.com/embed/yMLl7-aI_kc?start=687"
title="Stefano Fasciani demonstrating the 'TSAM' program"
/>

Fasciani's work made me realise it was possible to have the computer be responsible for finding parameter combinations that would produce an output with a certain perceptual value represented with audio descriptors. I was encouraged by this despite not having the programming skills to work with similar technologies such as neural networks or more general machine learning. Given these limitations, my motivations were to find or design my own strategies for exploring this idea in line with my creative coding skills that I had at the time.

### Changing the Balance of Computer and Human Agency
Alongside these influences spawned by engaging with the Fourses synthesiser, part of my motivation in Annealing Strategies was to re-approach some of the central aims in Stitch/Strata particularly in affording the computer *more* responsibility and agency in the compositional process. [Stitch/Strata]({m.ss}) was a frustrating and long compositional process that explored a number of tangential approaches before arriving at the final result. A significant factor in this frustrating experience of the compositional process was my inability to devise an algorithm which would allow the computer to make sophisticated high-level formal decisions that were compatible with my aesthetic preferences. What I found was that modelling my own high-level formal thinking led to an *infinite regress* of attempting to encode the complexity of choices that I make when composing intuitively and manually. My solution to these frustrations was to make the computer responsible for generating low-level and mid-level sections of music and for me to arrange, edit and apply further processing to these. Ultimately, my frustrations and compromises that I made were a result of not being able to express and encode a model of decision making and selection in the computer. In part, the inability to express what I wanted the computer to do was because I did not have any prior constraints or measurable outcomes on what I wanted to achieve creatively. In a sense, I was trying to experiment with the sample-based phonetic materials as well as encode, design and build a model at the same time. Thus, one of the main goals of Annealing Strategies was to create a more refined and constrained compositional possibilities and with a clearer set of intentions creatively. Taking this simple idea of a computer program working *searching* for a parameter combination that would result in a specific measurable perceptual outcome gave me this clarity and centered the compositional process technologically in trying to develop *simple compositional language* which would result in a *complex computer interpretation and result*. This is oppositional to the approach of [Stitch/Strata]({m.ss}), in which I was trying to take a complex compositional language and encode it into a simplistic computational model.

<!-- Alongside these aims, interacting with the Fourses synthesiser spawned some goals
- Material
    - Self-referencing material with a constrained space of possibilities. Fourses can produce a range of sounds that if used exhaustively would only be connected by their chaotic-ness.
    - At the same time, texturally rich and diverse within that space expressing the complexity of working within a tight set of parameters.
- Time
    - How can be managed such that...
    - Manually composing blocks or sections
    - Thinking in terms of composites
    - Working too much on the micro-structure in the hope that its sophistication will give rise to a perceivable and musically sophisticated macro-structure -->

## Â Synthesis and Annealing
Two technologies, the Fourses synthesiser and Simulated Annealing are central to Annealing Strategies. This section explains how these work in detail and also explain their connection to each other in relation to my aesthetic aims and goals.

### Fourses And An Interface For Control
Fourses is a synthsiser created by [Ciat-Lonbarde](https://www.ciat-lonbarde.net) otherwise known as Peter Blasser. 

It consists of four "Fourse" oscillators which are signal generating modules that have an upper and lower boundary. The oscillator oscillates between these boundaries with a triangle-like wave shape. Each Fourse is connected to the subsequent Fourse. The output of Fourse 1 for example determines the upper limit of Fourse 2. Fourse 2 would then have an effect on Fourses 3 and so on and so forth. As such, any modifications made within the system propagate throughout it in unpredictable ways. This makes Fourses hard to approach with the mindset of finding a specific sound, and instead encourages exploration within the complexity of this behaviour. A number of documents help to explain the underlying principle of Fourses including [the Fourses Manual](https://synthmall.com/ifm/ifmFRS.pdf) and the [FOURSES PAPERZ](http://www.ciat-lonbarde.net/fyrall/paperz/fourses/index.html). Despite the enigmatic nature FOURSES PAPERZ, images such as IMAGE 1 help in deciphering the underlying behaviour of this synth and how its interconnected and chaotic nature emerges.

<ImageMedia>
    <img slot="media" src="http://www.ciat-lonbarde.net/fyrall/paperz/fourses/06.gif">
    <p slot="caption">IMAGE 1: A visual depiction of the interconnected Fourses oscillators. Though the picture is unlabelled it depicts the boundaries of each Fourse oscillator "ricocheting" off another Fourse. Taken from <a href="http://www.ciat-lonbarde.net/fyrall/paperz/fourses/index.html">http://www.ciat-lonbarde.net/fyrall/paperz/fourses/index.html</a>.
</ImageMedia>

<!-- WIDGET: Web fourses.-->

The version of Fourses that was used for Annealing Strategies is included as a Max patch in the additional materials. In addition to this you may also want to experiment with a web version put together by [Oli Larkin](http://www.olilarkin.co.uk/). This can be found at [https://olilarkin.github.io/fourses/](https://olilarkin.github.io/fourses/).

### One-To-Many Mapping For Fourses
There are 24 parameters that control the Fourses synth and the unpredictable nature of changing even one parameter slightly makes it difficult to 'learn' the synthesiser in a way where you could predict the output for a set of inputs intuitively. I wanted to create a method of manual control for exploring different states of the synth where I was not required to interact with a single parameter at a time and instead could explore by moving "backward" and "forward" through a set of states. Toward this end I devised a one-to-many mapping strategy that constrained the number of states by reading through a procedural basis function graph. Using the input of a single linear dial, a deterministic "map" of values is used to control each parameter. VIDEO 1 is a screen capture emonstrating how this single input interface creates a one-to-many mapping. As the "origin" is changed the procedural basis function graph is scanned. Different basis are also demonstrated, showing the variety of relationships between parameters that can be arbitrarily created through this method. A set of 24 parameters are derived by creating the graph with 2x12 jitter matrix that is then flattened to a one dimensional row.

<VideoMedia>
    <video slot="media" controls loop>
        <source src="/as/jitbfg.webm" type="video/webm">  
        <p>Your browser doesn't support HTML5 video. Here is a <a href="/as/jitbfg.webm">link to the video</a> instead.</p>  
    </video>
    <p slot="caption">VIDEO 1: This screen capture shows the single input interface in practice.</p>
</VideoMedia>

The benefit of this approach is that the single input knob explores a subset of parameter combinations and the configuration of the procedural basis function determines these limitations. The range of possibilities is still vast, but the graph creates a set of states by imposing a type of shape and patterning to the parameters. To an extent this exploration was inspired by the work of Bowers et. al in "One Knob to Rule Them All: Reductionist Interfaces for Expansionist Research" and the various strategies and mappings that were explored between a single knob and several parameters for synthesis.

### Simulated Annealing
The single input interface was devised in the moment, as a way of exploring the sounds that could be made by the Fourses synthesiser in a semi-structured and computationally led manner. In doing this though I still had not explored my original question of how the computer could explore the vastness of possibilities that Fourses could produce, in particular finding those delicate and quiet sounds and the parameters that produce them. This led me down another path of investigation into the problem space of combinatorics and optimisation problems. Serendipitously I came across "Simulated Annealing". The naming of this algorithm is a reference to annealing in metallurgy, a process where material is heated and gradually cooled. At the start of this process, the molecules of that material can freely rearrange in a quasi-random fashion. As the material is slowly cooled, an optimal state crystallises and the tolerance for "weak" movements and thus bonds to be made are less likely to occur.

SA works by considering a set of discrete data points to have both a *state* and a *successor* or *neighbour*. The state is the value, or data associated to a data point and the neighbours are other states surrounding that one. The neighbours can be determined a number of ways, such as the organisation of points in a graph or spatially organising the points in two or three dimensions. Given this dataset simulated annealing begins its process by selecting a random state to start with. An initial *temperature* parameter is set at this point an important concept that will be explained shortly. At each *iteration*, a new nearby state is selected and the data associated to that state is compared with the previous state. If the movement to this new state results in a positive difference, then that move is considered "good" and is retained. If the move produces a negative difference the move is considered "bad". Instead of simply rejecting the bad move, there is a probability that this move is instead retained. This probability is determined by the [Boltzmann Distribution](https://en.wikipedia.org/wiki/Boltzmann_distribution) which is the function epsilon to the power of the change in energy divided the temperature of the system. Each iteration reduces this temperature depending on the cooling rate, meaning that as the algorithm progresses fewer bad moves are kept. The rationale is that while hill climbing algorithms lack the sophistication to escape local minima and maxima, simulated annealing can escape these temporarily to search for global optimal states when the temperature is high. As the temperature reduces these explorative moves are less likely to occur. In FIGURE 1, a flowchart describes the simulated annealing.

<ImageMedia>
    <img slot="media" src="https://upload.wikimedia.org/wikipedia/commons/d/d5/Hill_Climbing_with_Simulated_Annealing.gif">
    <p slot="caption">FIGURE 1: A flowchart describing the steps of the Simulated Annealing algorithm.</p>
</ImageMedia>

Simulated annealing can be applied to many problems across different domains including finding the minimum or maximum value given a set of values, such as in this weather data (see FIGURE 2) or solving the "travelling salesman problem" in which an optimally short journey is designed between a set of spatially dispersed nodes (see FIGURE 3). An interactive example by "Nayuki" uses simulated annealing to [reconstruct a digitally "shredded" image](https://www.nayuki.io/page/image-unshredder-by-annealing). This particular example is apt for demonstrating how the parameters of the algorithm: starting temperature, cooling rate and number of iterations can effect its result and success.

<ImageMedia>
    <img slot="media" src="https://upload.wikimedia.org/wikipedia/commons/d/d5/Hill_Climbing_with_Simulated_Annealing.gif">
    <p slot="caption">FIGURE 2: The highest data point in weather data being located through simulated annealing. Taken from <a href="https://commons.wikimedia.org/wiki/File:Hill_Climbing_with_Simulated_Annealing.gif">Kingpin13</a>, CC0, via Wikimedia Commons  </p>
</ImageMedia>

<ImageMedia>
    <img slot="media" src="https://upload.wikimedia.org/wikipedia/commons/1/1e/3D_TSP_solved_with_simulated_annealing_2.5_MB.gif">
    <p slot="caption">FIGURE 3: The travelling salesman problem being solved by simulated annealing. Panchotera~enwiki, CC BY-SA 4.0 https://creativecommons.org/licenses/by-sa/4.0, via Wikimedia Commons </p>
</ImageMedia>

### Combining Simulated Annealing With The Single Input Interface
In "Annealing Strategies" simulated annealing is used in conjunction with the single input interface to create a system of control and automatic computational exploration of parameter combinations. Using an audio descriptor for the perceptual loudness of the output of the Fourses, simulated annealing is used to discover how the single input interface that "scrubs" through a procedural basis graph can produce perceptually quiet outputs. At its core, the SA algorithm is optimising the loudness value by changing the input value, with the black box of entangled and coupled parameters sitting between those two as a complex function.

A step-by-step procedure is followed to realise this.

1. Generate an initial value for the "origin". This dictates the starting parameters generated from the procedural basis function.
2. Take the loudness descriptor's values in decibels and pass that value to the simulated annealing algorithm.
3. Generate a new value for the origin creating a new parameter set.
4. Take the loudness descriptor's value in decibels and pass that value to the simulated annealing algorithm.
5. If the change between steps 1 and 4 rendered a quieter output (lower loudness value) keep that change, otherwise, return to the parameter combination at step 1.
6. Lower the temperature of the annealing process according to the cooling rate.
6. Return to step 2.

<!-- LINK: link to reflective part of section -->
This process has several hyperparameters: learning rate, cooling rate and the maximum temperature. Changing these can alter the outcome of using simulated annealing in a number of ways, perhaps most importantly by effecting the success of the algorithm in terms of discovering the most optimal state. If the system is cooled too quickly, or the temperature does not have a sufficiently high starting temperature then the algorithm is less likely to discover the global optimum. The learning rate is my own addition to the algorithm which determines the maximum distance from the current state the new state can be. This is scaled according to the current temperature divided by the starting temperature of annealing making it such that the algorithm can choose states that are in close proximity while the temperature is high, and only nearby states when the temperature is low. The musical and compositional affect of these parameters is discussed in the reflective part of this chapter.

An iteration of "Annealing Strategies" as a work is created by running this algorithm and recording the path that it takes in annealing and discovering an optimal solution. As a result, a number of aspects of the technical implementation contribute to the shape of the work.

## Selecting An Output From The Simulated Annealing System

"Annealing Strategies" is a single output from the system that I selected. This was judged by how well it suited my conceptual goals I made prior to the compositional process. Hundreds of iterations were made throughout this and many of these were auditioned and sorted into a folder of "bad" and "good" iterations. Some of these bad iterations can be found in AUDIO 1, AUDIO 2, and AUDIO 3 alongside explanations of why they were classified in this way. The iterations are named by the computer according to the random seed which is used, the type of procedural noise basis and then a random identifier.

<Waveform
title="AUDIO 1 (592_noise.simplex_529155534)"
file="https://f000.backblazeb2.com/file/jbphd-pub/as/592_noise.simplex-am.mp3"
peaks="https://f000.backblazeb2.com/file/jbphd-pub/as/592_noise.simplex-am.dat"
id="audio1"
/>

In iteration [592_noise.simplex_529155534]({m.as}#audio1) there is little variation from the initial state which is set up at the start. In this case my understanding is that the algorithm failed to discover any quiet states in its search or perhaps the algorithm parameters that were used used too fast a cooling rate or not a high enough initial temperature.

<Waveform
title="AUDIO 2 (453_noise.simplex_529163614)"
file="https://f000.backblazeb2.com/file/jbphd-pub/as/453_noise.simplex-am.mp3"
peaks="https://f000.backblazeb2.com/file/jbphd-pub/as/453_noise.simplex-am.dat"
id="audio2"
/>

The sound which dominates the first two minutes of iteration [453_noise.simplex_529163614]({m.as}#audio2) exhibits morphological and textural properties that I liked. This kind of sound was what I initially intended for the simulated annealing to be able to discover as it ran. However, this initial sound is never altered significantly until around 2:12, at which point a low pitched and wandering bass sound is introduced. The changes at this point seem abrupt and it contributes to a behaviour that is more like a random search than a controlled and increasingly focused progression towards quieter sounds.

<Waveform
title="AUDIO 3 (738_noise.simplex_529152854.aiff)"
file="https://f000.backblazeb2.com/file/jbphd-pub/as/738_noise.simplex-am.mp3"
peaks="https://f000.backblazeb2.com/file/jbphd-pub/as/738_noise.simplex-am.dat"
id="audio3"
/>

Iteration [738_noise.simplex_529152854]({m.as}#audio3) possesses a pitched "whine" from the start which is the most pervasive musical element throughout. There is variation to this sound and for some periods of time after this shorter more iterative sounds emerge in an organic manner. This particular sound world which is created suited the type of sounds I wanted the annealing algorithm to find. However, at 3:41, a new increasingly pitched sound emerges which is relatively unaltered for the remainder of the iteration. While the first section was to some degree a kind of sound that was sympathetic to my initial aims, the overall structure of this iteration does not satisfy the progression from louder to softer sounds I was aiming to produce.

A number of good iterations were made, and those that were not chosen as the single "best" output will be discussed briefly in ["Issues of Control and Intervention"]({m.as}#issues-of-control-and-intervention). The selected output to be "Annealing Strategies" was iteration 738_noise.simplex_529135520 which can be heard in AUDIO 4.

<Waveform
title="AUDIO 4: 'Annealing Strategies' (738_noise.simplex_529135023)"
file="https://f000.backblazeb2.com/file/jbphd-pub/as/annealing_strategies.mp3"
peaks="https://f000.backblazeb2.com/file/jbphd-pub/as/annealing_strategies.dat"
id="audio4"
segments={segs4}
/>

<!-- LINKS: link to specific markers and segment markers -->
This iteration possessed a sophisticated macro-structure that was satisfactory according to my original aims and goals with this piece. Compared to any of the other iterations, [738_noise.simplex_529135023]({m.as}#audio4) exhibited a natural and organic taper across its duration from initially chaotic and bombastic sounds towards a narrow and controlled final section focused toward intricate and quiet sounds. This iteration exhibits an antagonistic relationship between pitched and noise material. Through the simulated annealing behaviour the relationship between these two sound types is maintained while creating development within each of them.

The opening section from 0:00 to approximately 1:10 presents a dense mixture of interwoven noise and pitched elements. At 1:11, the opening section is concluded, demarcated by a new longer section of primarily noise-based material. From this point onwards there are increasingly longer spans of time that alternative between noise or pitched material with less interleaving of these two sound types. Within each of these longer sections, the prominent sound type is developed further and iterated through the simulated annealing algorithm's behaviour. The period between 1:30 and 1:50 is an example of this.

At 2:39 there is a longer passage that has a notable change in the way that pitched and noise-based sounds are juxtaposed. From this point onwards their presentation is purer and the interspersing of those two sound types is largely gone. Instead, the behaviour is more homogenous. For example, from 2:39 to 2:43 noise-based material is foregrounded without any semblance of the previous pitch material present. After this at 2:43, the pitch material rapidly returns and the noise dissipates till 2:47. A similar alternation of homogenous sound type presentation occurs again from the period of 2:47 to 2:57. As this behaviour unfolds in the macro-structure of this iteration, there are noticeable changes to the pitch and noise-based material sound types. The noise becomes more controlled and quieter and the presence of transients disappears. This development can be seen when comparing noise-based sounds from 1:13 to 1:17 to that from the previously mentioned 2:39 to 2:43 section. Pitched material becomes less striated and erratic and progresses towards quasi-melodic chromatic phrases. This can be seen when comparing from 0:46 to 0:53 and from 2:48 to 2:55. 

In conjunction with different classes of sounds developing under the control of the simulated annealing system, unintended and emergent "sectional borrowing" was produced in this iteration. The opening phrase for example is almost mimicked at 0:26, with the contour and sound types between these two moments being very similar. Another example of this occurs prominently between the two moments at 2:38 and 2:46. Between these two sections the gesture is exactly the same, despite this kind of phrase repetition not being explicitly coded into the simulated annealing algorithm. A final example of this emergent behaviour occurs between the two sections at 0:20 and 0:55 that contain a short exhibition of low pitch material.

Other iterations rarely possessed such sophisticated structural properties and this was a significant factor in me selecting [738_noise.simplex_529135023]({m.as}#audio4). These features were not manually composed and *emerged* from the simulated annealing system controlling the Fourses synth. 

## Reflecting On Issues Of Control and Intervention
Annealing Strategies was a successful piece artistically for me and fostered a compositional workflow where a significant amount of agency was given to the computer without having to sacrifice sophistication in the music. I endeavoured to achieve this in [Stitch/Strata]({m.ss}) but was often unsuccessful in my attempts to have the computer be responsible for increasingly abstract and complex musical aspects, such as high-level form. The compositional blockages of that project resulted in me moving toward a compositional process based on manually arranging small computer generated phrases and gestures of descriptor-driven concatenative synthesis outputs. That workflow required rapid iteration between generating those phrases and gestures, auditioning them and returing to the generation stage in order to make sense of the material and then make further decisions about how it would be used in the composition. It also required a large degree of intuition and choices on aspects such as the ordering of samples and sound manipulations applied in post-production. Annealing Strategies was entirely different to this, with both the high-level and low-level formal decision making performed by the computer through the simulated annealing process and much of the detail in the surface of the music being resolved by the system automatically.

Giving away control and agency fundamentally altered my interaction with sound materials and the ways that I was able to influence the compositional result. Without a mechanism for interacting with the system while it ran my main influence on the computer was to alternate between listening to an output of the system and to modify the parameters or the system itself. Examples of this method of interaction and control was by changing the hyperparameters of the simulated annealing process: cooling rate, starting temperature, learning rate as well as the type and random seed for the procedural noise graph. Instead of thinking about how I could achieve specific sonic moments, I was focused on creating a set of conditions in which a particular overarching musical behaviour would emerge. The system would then be responsible for creating detail and sophistication within the constraints of that process. This compositional workflow relates directly back to the notion of "lose control gain influence", discussed in ["Situating My Practice"]({m.ca}#situating-my-practice). By affording the computer the role of creating structure, I was able to achieve a coherency at many hierarchical levels of form without having to design specific musical moments or rely on modelling my intuitive and manual decision making. This takes away the possibility of honing a specific musical section or idea that I can imagine or plan, but allows the computer to produce surprising and unanticipated outcomes that challenge my compositional tendencies.

### Iterating On Approaches From Annealing Strategies
While there was a high degree of success in this approach it was not a generalisable workflow that I could apply to different materials or conceptual goals in the future. The combination of the Fourses synth, the simulated annealing algorithm and the single input interface came together almost serendipitously without having to explore a number of other strategies for achieving my goals. In a sense, I was fortunate that these technologies worked together and were well-suited to the aesthetic and conceptual aims of the piece. Simulated annealing, which had a significant influence on the results produced by the system was suited to the specific conceptual and artistic aims of this project but is not necessarily appropriate for all types of creative aims I will have in the future. Furthermore, the single input interface created a novel one-to-many mapping for the parameters of the Fourses synth but is not something I would use in every scenario where that issue of control arises.

Another aspect which makes it difficult to carry forward the successes of Annealing Strategies into future projects is the annealing algorithm. This algorithm has a scope of problems it solves and these serviced the specific conceptual ideas I had well. The confluence of these two things meant that I accepted and embraced the influencing properties of the algorithm into the work. For example, the convergent behaviour of simulated annealing produced results where in each iteration the Fourses synth begins by modifying the parameters wildly and as the algorithm performs its function, the scope of sounds it produces is reduced. This behaviour was compatible with the conceptual vision I had for the piece, and so much of the algorithm inflects the work as a result. I can imagine a scenario in the future where a more complex and non-linear formal structure is desired where simply running the algorithm will not be able to service those aims well. 

Furthermore, there were moments in the creative process where I was not sure that the algorithm would be able to produce a satisfying piece in one iteration. I had many good iterations before that with novel characteristics but none of them were convincing to me as standalone pieces. Prior to producing [738_noise.simplex_529135023]({m.as}#audio4), I anticipated that to get to a satisfying solution I would have to edit and stitch together sections from good iterations. For me though, doing this would have made the use of simulated annealing arbitrary and pointless. If I had not used the inherent behaviour of the simulated annealing algorithm and let it influence the high and low-level form, then another algorithm for the same purpose and built from the ground-up would probably have been more customisable, controllable and required less blind experimentation to get it to the final result that I found. I wanted the algorithm to shape the piece entirely and on its own, and editing together numerous takes to achieve a structure that progresses from loud to quiet parameter combinations of the fourses synth would have betrayed my initial conceptual aims.

The convergence of many aspects made Annealing Strategies successful but not a replicable workflow that could be iterated on in the future. After I had completed this project, I felt as if I had explored the semi-supervised and unsupervised range of the spectrum of computer agency. This left not much room for me putting my own influence into the creative process outside. This avoided many of the issues I came across in [Stitch/Strata]({m.ss}) but also raised new questions about how much immediacy and influence I would like to retain in future works. As such, my motivations from this point onwards were centred in finding ways that editing, intuition and my control could be combined with the agency of the computer such that a range of relationships and configurations in the spectrum of control could be explored, rather than this relationship being fixed for entire creative process.

## Related Links and Media
I gave a presentation at the <a href="http://electricspring.co.uk/electric-spring-2018/">2018 Electric Spring Creative Coding Lab Symposium</a> that discussed the motivations and creative process for Annealing Strategies. While this video at times skims over detail due to time constraints of the presentation it is documentation that supports this work and thus deserves inclusion in this thesis.

<YouTube url="https://www.youtube.com/embed/Ro30O9u7l8M"/>

<!-- ## Technical Improvements and Considerations
Looking at the technical implementation almost three years after its development, it is fairly weak but is nonetheless a reflection of my skills and abilities at that time and working at these limitations.
    - The behaviour of simulated annealing in this application is very noticeable in the surface of the music. In particular an audible "clock" is heard for each simulated annealing "epoch". This could be removed by reconfiguring the implementation, but nonetheless there is a kind of demarcated determinism to how the algorithm iteratively performs its function.
    - There is very loose and non-deterministic synchronisation between analysis windows with the loudness audio descriptor and epochs of the simulated annealing.
    - The parameter changes for the Fourses synth are filtered to remove sharp changes. This removes an audible "click" every time a parameter is changed but creates a slight interpolation between the old state and the new state which is captured in the analysis.
        - One solution would be to perform the whole process offline and then render the result out with seamless audio-rate changes.
        - These concerns are a reflection of the way I would approach this piece and concept now, and do not account for the explorative process that I went through in solving these problems on-the-fly. Ultimately, the piece produced satisfying musical phenomena, regardless of the technical perfection of the way I was working. -->

<NextSection 
next="Refracted Touch"
link={m.rt}
/>

<style>
    video {
        display: block;
        margin: 0 auto;
        width: 50%;
        height: auto;
    }
</style>
    