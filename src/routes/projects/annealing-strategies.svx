<script>
	import NextSection from "$lib/components/NextSection.svelte";
    import {metadata as m} from "../directory.svx";
    import VideoMedia from "$lib/components/VideoMedia.svelte";
    import VideoMedia2 from "$lib/components/VideoMedia2.svelte";
    import ImageMedia from "$lib/components/ImageMedia.svelte";
    import ImageMedia2 from "$lib/components/ImageMedia2.svelte";
    import YouTube from "$lib/components/YouTube.svelte";
    import Caption from "$lib/components/Caption.svelte";
    import Waveform from "$lib/components/Waveform.svelte";

    import { segs4 } from "$lib/data/as.js";
</script>

# Annealing Strategies

<Waveform
title='Annealing Strategies (738_noise.simplex_529135023)'
caption='AUDIO 1'
file="/pieces/as.mp3"
peaks="/pieces/as.dat"
id="aud1"
/>
Annealing Strategies is a piece that is created by a content-aware program. It uses an audio descriptor to measure the perceptual loudness of a "Fourses" synthesiser alongside "Simulated Annealing" (SA), an optimisation technique that over time discovers what combination of complex coupled parameters for the synthesiser create the quietest possible output. A number of iterations of this work were created by the system and through curation of those outputs and fine tuning of the SA algorithm I arrived at a final rendition of the work.

## Motivations and Influences
The initial inspiration for this piece emerged when I came across a digital implementation of a "Fourses" synthesisers on the [cycling 74](https://cycling74.com/forums/recreating-a-horsefourses-oscillator/) forums. I had never come across this particular synthesiser before, and there were two aspects that made me inquisitive and wanting to use this synth for *something* creative without any specific ideas for what that project would be. Firstly, experimenting with the [collectively designed Max patch](https://cycling74.com/forums/recreating-a-horsefourses-oscillator/replies/1#reply-58ed2132c2991221d9cc767c) demonstrated the range of sounds it could produce, including noisy, pitched, harmonic and inharmonic timbres. In particular the quietest sounds interested me as they were novel and hard to discover amongst numerous loud sounds. Furthermore, the quieter states were unstable in nature and would sometimes produce localised morphological variation. Secondly, listening to the synthesiser and interacting with its 24 parameters inspired a technological question about how a computer might be able to *find* parameter combinations that would result in specific perceptual outputs. From this idea I imagined a piece where the synthesiser is seeded in an untamed and loud state and the computer explores combinations of parameters to gradually find a quiet state. I imagined that this process would shape the structure of the piece and the journey from the starting point to the "solution" would be able to create a simple and effective linear structure.

As I researched topics related to these interests, I came across Stefano Fasciani, who in his work has developed new perceptually grounded interfaces for synthesisers. In "TSAM: A Tool for Analyzing, Modelling And Mapping The Timbre Of Sound Synthesizers" Fasciani (2016) describes a program that uses audio descriptors and neural networks to "enable the study of how changes to a synthesis parameter affect timbral descriptors". This creates the possibility for real-time interaction with a synthesiser by navigating through a visual space that distributes timbral possibilities spatially rather than interacting with the individual parameters. In [VIDEO 1]({m.as}#vid1), Fasciani demonstrates how this works by using TSAM to analyse many combinations of parameters of a synthesiser and the sound it produces. He then changes the parameters by exploring a two dimensional space.

<YouTube 
url="https://www.youtube.com/embed/yMLl7-aI_kc?start=687"
title="Stefano Fasciani demonstrating the 'TSAM' program"
caption="Stefano Fasciani demonstrating the 'TSAM' program"
figure="VIDEO 1"
/>

Fasciani's work made me realise it was possible to have the computer be responsible for finding parameter combinations that would produce an output with a specific perceptual quality represented by audio descriptors. I was encouraged by this, despite not having the programming skills to work with technologies such as neural networks or more machine learning. Given these limitations, my motivations were to find or design my own strategies for exploring this idea in line with my capabilities at the time.

### Changing the Balance of Computer and Human Agency
Alongside these influences spawned by engaging with the Fourses synthesiser, part of my motivation in Annealing Strategies was to re-approach some of the central aims in Stitch/Strata particularly in affording the computer *more* responsibility and agency in the compositional process. [Stitch/Strata]({m.ss}) was a frustrating and long compositional process that explored a number of tangential approaches before arriving at the final result. A significant factor in this frustrating experience of the compositional process was my inability to devise an algorithm which would allow the computer to make sophisticated high-level formal decisions that were compatible with my aesthetic preferences. What I found was that modelling my own high-level formal thinking led to an *infinite regress* of attempting to encode the complexity of choices that I make when composing intuitively and manually. My solution to these frustrations was to make the computer responsible for generating low-level and mid-level sections of music and for me to arrange, edit and apply further processing to these. Ultimately, my frustrations and compromises that I made were a result of not being able to express and encode a model of decision making and selection in the computer. In part, the inability to express what I wanted the computer to do was because I did not have any prior constraints or measurable outcomes on what I wanted to achieve creatively. In a sense, I was trying to experiment with the sample-based phonetic materials *and* encode, design and build a model for the computer to work with these at the same time. 

One of the main goals of Annealing Strategies was to create more refined and constrained compositional possibilities with a clearer set of intentions creatively. Taking this simple idea of a computer program working *searching* for a parameter combination that would result in a specific measurable perceptual outcome gave me this clarity and centred the compositional process technologically in trying to develop *simple compositional language* which would result in a *complex computer interpretation and result*. This is oppositional to the approach of [Stitch/Strata]({m.ss}), in which I was trying to take a complex compositional language and encode it into a simplistic computational model.

## Â Synthesis and Annealing
Two technologies, the Fourses synthesiser and Simulated Annealing are central to Annealing Strategies. This section explains how these work in detail and also explain their connection to each other in relation to my aesthetic aims and goals.

### Fourses And An Interface For Control
Fourses is a synthsiser created by [Ciat-Lonbarde](https://www.ciat-lonbarde.net) otherwise known as Peter Blasser. It consists of four "Fourse" oscillators that generates triangle-shaped wave between an upper and lower boundary. The output for each Fourse is connected to the subsequent Fourse as a parametric control for the boundaries while also being siphoned off as an audio output. For example, The output of the first Fourse  determines the upper limit of Fourse 2. Fourse 2 would then have an effect on Fourses 3 and so on and so forth. As such, any modifications made within the system propagate throughout it in unpredictable ways. This makes it difficult to find specific sounds with Fourses and instead encourages exploration within the complexity of this behaviour. A number of documents help to explain the underlying principle of Fourses including [the Fourses Manual](https://synthmall.com/ifm/ifmFRS.pdf) and the [FOURSES PAPERZ](http://www.ciat-lonbarde.net/fyrall/paperz/fourses/index.html). Despite the enigmatic nature FOURSES PAPERZ, images such as [IMAGE 1]({m.as}#img1) help in deciphering the underlying behaviour of this synth and how its interconnected and chaotic nature emerges.

<ImageMedia2 
url="http://www.ciat-lonbarde.net/fyrall/paperz/fourses/06.gif"
caption='A visual depiction of the interconnected Fourses oscillators. Though the picture is unlabelled it depicts the boundaries of each Fourse oscillator "ricocheting" off another Fourse. Taken from <a href="http://www.ciat-lonbarde.net/fyrall/paperz/fourses/index.html">http://www.ciat-lonbarde.net/fyrall/paperz/fourses/index.html</a>'
figure="IMAGE 1"
id="img1"
htmlCap={true}
/>

The Max patch version of Fourses that was used for Annealing Strategies can be <a href="/as/fourses.maxpat" download="/as/fourses.maxpat">downloaded by clicking this link</a>. In addition to this you may also want to experiment with a web version put together by [Oli Larkin](http://www.olilarkin.co.uk/). This can be found at [https://olilarkin.github.io/fourses/](https://olilarkin.github.io/fourses/).

### One-To-Many Mapping For Fourses
There are 24 parameters that control the Fourses synth and the unpredictable nature of changing one parameter only slightly makes it difficult to "learn" how they effect the output sound. I wanted to create a method of manual control for exploring different states of the synth where I was not required to interact with a single parameter at a time and instead could explore by moving "backward" and "forward" through a set of states. Toward this end I devised a one-to-many mapping strategy that constrained the number of states by reading through a procedural basis function graph. Using the input of a single linear dial, a deterministic "map" of values is used to control each parameter. [VIDEO 2]({m.as}#vid2) is a screen capture demonstrating how this single input interface creates a one-to-many mapping. As the "origin" is changed the procedural basis function graph is scanned. Different basis are also demonstrated, showing the variety of relationships between parameters that can be arbitrarily created through this method. A set of 24 parameters are derived by creating the graph with 2x12 jitter matrix that is then flattened to a one dimensional row.

<VideoMedia2
url="/as/jitbfg.webm"
figure="VIDEO 1"
caption="A screen capture demonstrating the single input interface in practice."
id="vid1"
/>

The benefit of this approach is that the single input allows one to explore a subset of parameter combinations more easily than fine tuning the individual parameters while giving up some specific control. Furthermore,  the configuration of the procedural basis function can create a variety of novel combinations of parameters very quickly. This exploration was inspired by the work of Bowers et. al (2016) and their various strategies that were explored for mapping a single knob and several parameters for synthesis.

### Simulated Annealing
The single input interface was devised as a way of exploring the sounds that could be made by the Fourses synthesiser in a semi-structured and computationally led manner. However, I still had not explored my original question of how the computer could explore the relationship between parameters and the sound that Fourses could produce, in particular finding delicate and quiet sounds. This led me on another path of research into combinatorics and optimisation problems. Serendipitously I came across "Simulated Annealing" (SA). SA is named in reference to the process annealing in metallurgy where material is heated and gradually cooled in order to find an arrangement of molecules that is optimally strong. At the start of this process molecules can freely rearrange in a quasi-random fashion. As the material is slowly cooled, an optimal state crystallises and the tolerance for "weak" movements and thus bonds to be made are less likely to occur. 

<!-- REVIEW: function to the epsilon blah blah blah -->
SA works by considering a set of discrete data points to have both a *state* and a *successor* or *neighbour*. The state is the value, or data associated to a data point and the neighbours are other states surrounding that one. The neighbours can be determined a number of ways, such as the organisation of points in a graph or spatially organising the points in two or three dimensions. Given this dataset SA begins its process by selecting a random state to start with. An initial *temperature* parameter is set at this point. At each *iteration*, a new nearby state is selected and the data associated to that state is compared with the previous state. If the movement to this new state results in a positive difference between the two data points, then that move is considered "good" and is retained. If the move produces a negative difference the move is considered "bad". Instead of simply rejecting the bad move, there is a probability that this move is instead retained in the process. This probability is determined by the [Boltzmann Distribution](https://en.wikipedia.org/wiki/Boltzmann_distribution) which is the function epsilon to the power of the change in energy divided the temperature of the system. Each iteration reduces this overall temperature of the system depending on the *cooling rate*, meaning that as the algorithm progresses bad moves are less likely to be retained. The rationale is that while hill climbing algorithms can get stuck in local minima and maxima, SA can temporarily escape them to search for global optimal states when the temperature is high. As the temperature lowers, fewer bad states are kept, and the algorithm will have ideally had enough *exploration* to discover the global maximum.  In [IMAGE 2]({m.as}#img2), a flowchart describes the steps of the simulated annealing process.

<ImageMedia2 
url="/as/annealing-flowchart.svg"
caption="A flowchart describing the steps of the simulated annealing algorithm."
figure="IMAGE 2"
id="img2"
/>

Simulated annealing can be applied to many problems across different domains including finding the minimum or maximum value given a set of values, such as in this weather data (see [IMAGE 3]({m.as}#img3)) or solving the "travelling salesman problem" in which an optimally short journey is designed between a set of spatially dispersed nodes (see [IMAGE 4]({m.as}#img4)). An interactive example by "Nayuki" uses simulated annealing to [reconstruct a digitally "shredded" image](https://www.nayuki.io/page/image-unshredder-by-annealing). This particular example is apt for demonstrating how the parameters of the algorithm can effect the success of the simulated annealing.

<ImageMedia2 
url="https://upload.wikimedia.org/wikipedia/commons/d/d5/Hill_Climbing_with_Simulated_Annealing.gif"
htmlCap={true}
caption='The highest data point in weather data being located through simulated annealing. Taken from <a href="https://commons.wikimedia.org/wiki/File:Hill_Climbing_with_Simulated_Annealing.gif">Kingpin13</a>, CC0, via Wikimedia Commons'
figure="IMAGE 3"
id="img3"
/>

<ImageMedia2 
url="https://upload.wikimedia.org/wikipedia/commons/1/1e/3D_TSP_solved_with_simulated_annealing_2.5_MB.gif"
htmlCap={true}
caption='The travelling salesman problem being solved by simulated annealing. Panchotera~enwiki, CC BY-SA 4.0 <a href="https://creativecommons.org/licenses/by-sa/4.0">https://creativecommons.org/licenses/by-sa/4.0</a>, via Wikimedia Commons'
figure="IMAGE 4"
id="img4"
/>

### Combining Simulated Annealing With The Single Input Interface
In [Annealing Strategies]({m.as}) simulated annealing is used in conjunction with the single input interface to create a system of control and automatic computational exploration of parameter combinations. Using an audio descriptor for the perceptual loudness of the output of the Fourses, simulated annealing "discovers" how the single input interface that traverses through a procedural basis graph can produce perceptually quiet outputs. At its core, the SA algorithm is optimising the loudness value by changing the input value, with the black box of entangled and coupled parameters sitting between those two as a complex function.

A step-by-step procedure is followed to realise this.

1. Generate an initial value for the "origin". This dictates the starting parameters generated from the procedural basis function.
2. Take the loudness descriptor's values in decibels and pass that value to the simulated annealing algorithm.
3. Generate a new value for the origin creating a new parameter set.
4. Take the loudness descriptor's value in decibels and pass that value to the simulated annealing algorithm.
5. If the change between steps 1 and 4 rendered a quieter output (lower loudness value) keep that change, otherwise, return to the parameter combination at step 1.
6. Lower the temperature of the annealing process according to the cooling rate.
6. Return to step 2.

<!-- LINK: link to reflective part of section -->
This process has several hyperparameters: learning rate, cooling rate and the maximum temperature. Changing these can alter the outcome of using simulated annealing in a number of ways, perhaps most importantly by effecting the success of the algorithm in terms of discovering the most optimal state. If the system is cooled too quickly, or the temperature does not have a sufficiently high starting temperature then the algorithm is less likely to discover the global optimum. The learning rate is my own addition to the algorithm which determines the maximum distance from the current state the new state can be. This is scaled to the current temperature, making it such that the algorithm can select new states at each iteration which are not necessarily direct neighbours but are in close proximity and only nearby states when the temperature is low.

An iteration of [Annealing Strategies]({m.as}) is created by running this algorithm and recording the audio output produced while the SA solves for an optimal solution. As a result, the technical implementation contributes significantly to the shape of the work and how I interacted with the system to compose.

## Selecting An Output From The Simulated Annealing System

[Annealing Strategies[({m.as})] is a single output from the system which I select after auditioning. The selection process was judged by how well it suited my conceptual goals I made prior to the compositional process as well as how satisfying it was in relation to my aesthetic preferences. Hundreds of iterations were made from this back and forth, and were sorted into "bad" and "good" iterations. Some of these bad iterations can be found in [AUDIO 2]({m.as}#aud2), [AUDIO 3]({m.as}#aud3), and [AUDIO 4]({m.as}#aud4) alongside explanations of why they were classified in this way. The iterations are named by the computer according to the random seed which is used, the type of procedural noise basis and then a random identifier.

<Waveform
title="592_noise.simplex_529155534"
caption='AUDIO 2'
file="/as/592_noise.simplex-am.mp3"
peaks="/as/592_noise.simplex-am.dat"
id="aud2"
/>

In iteration [592_noise.simplex_529155534]({m.as}#aud2) there is little variation from the initial state which is set up at the start. In this case my understanding is that the algorithm failed to discover any quiet states in its search or that too fast a cooling rate or not a high enough initial temperature were set.

<Waveform
title="453_noise.simplex_529163614"
caption='AUDIO 3'
file="/as/453_noise.simplex-am.mp3"
peaks="/as/453_noise.simplex-am.dat"
id="aud3"
/>

The sound which dominates the first two minutes of iteration [453_noise.simplex_529163614]({m.as}#aud3) exhibits morphological and textural properties that I liked. This kind of sound was what I initially intended for the simulated annealing to be able to discover as it ran. However, this initial sound is never altered significantly until around 2:12, at which point a low pitched and wandering bass sound is introduced. The changes at this point seem abrupt and it contributes to a behaviour that is more like a random search than a controlled and increasingly focused progression towards quieter sounds.

<Waveform
title="738_noise.simplex_529152854.aiff"
caption='AUDIO 4'
file="/as/738_noise.simplex-am.mp3"
peaks="/as/738_noise.simplex-am.dat"
id="aud4"
/>

Iteration [738_noise.simplex_529152854]({m.as}#aud4) possesses a pitched "whine" from the start which is the most pervasive musical element throughout. There is variation to this sound and for some periods of time after this, shorter iterative sounds emerge. I found this particular sound world aesthetically satisfying. However, at 3:41, a new pitched sound emerges which is relatively unaltered for the remainder of the iteration. While the first section was a result that I liked, the overall structure of this iteration was unsatisfactory.

A number of good iterations were made, and those that were not chosen as the single "best" output will be discussed briefly in ["Issues of Control and Intervention"]({m.as}#issues-of-control-and-intervention). The output that was selected to be [Annealing Strategies]({m.as}) was iteration 738_noise.simplex_529135520 which can be heard in [AUDIO 5]({m.as}#aud5).

<Waveform
title="Annealing Strategies (738_noise.simplex_529135023)"
caption='AUDIO 5'
file="/as/annealing_strategies.mp3"
peaks="/as/annealing_strategies.dat"
id="aud5"
segments={segs4}
/>

This iteration possessed a sophisticated macro-structure that satisfied my original aims and goals. Compared to any of the other iterations, [738_noise.simplex_529135023]({m.as}#aud5) exhibited a natural and organic taper from initially chaotic and bombastic sounds towards a narrow and controlled final section focused toward intricate and quiet sounds. Many other iterations would seem to be stuck and focused on exploring a small range of parameters, while this iteration does not have that problem and the overall linear form is ornamented by complex and novel diversions. In particular, this iteration exhibited a set of behaviours in which pitched and noise-based material are put in opposition with each other. At the higher formal level, the overall loudness is decreasing, while different sections emerge in which these two material groups are portrayed antagonistically and exhibit their own development.

For example, the opening section from 0:00 to approximately 1:10 presents a dense mixture of interwoven noise and pitched elements. At 1:11, the opening section is concluded, demarcated by a new longer section of primarily noise-based material. From this point onwards there are increasingly longer spans of time that alternate between noise and pitched material with less interleaving. Within each of these longer sections, the prominent sound type is developed further. The period between 1:30 and 1:50 is an example of this.

At 2:39 there is a longer passage changes the way that pitched and noise-based sounds are juxtaposed. From this point onwards their presentation is purer and the interspersing of those two sound types is largely gone. Instead, the behaviour is more homogenous. For example, from 2:39 to 2:43 noise-based material is foregrounded without any semblance of the previous pitch material present. After this at 2:43, the pitch material rapidly returns and the noise dissipates till 2:47. A similar alternation of homogenous sound type presentation occurs again from the period of 2:47 to 2:57. As this behaviour unfolds in the macro-structure of this iteration, there are noticeable evolutions to the pitch and noise-based material sound types. The noise becomes more controlled and quieter and the presence of transients disappears. This can be heard when comparing noise-based sounds from 1:13 to 1:17 to that from the previously mentioned 2:39 to 2:43 section. Pitched material becomes less striated and erratic and progresses towards quasi-melodic chromatic phrases. Again this can be heard when comparing from 0:46 to 0:53 and from 2:48 to 2:55. 

In conjunction with different classes of sounds developing under the control of the SA, unintended and emergent "sectional borrowing" was produced in this iteration. The opening phrase for example is almost mimicked at 0:26, with the contour and sound types between these two moments being very similar. Another example of this occurs prominently between two moments at 2:38 and 2:46. In both of these sections the gesture is extremely similar, despite this kind of phrase repetition not being explicitly coded into SA. A final example of this emergent "borrowing" behaviour occurs between the two sections at 0:20 and 0:55 that contain a short passage of low pitch material.

Other iterations rarely possessed such sophisticated structural properties and this was a significant factor in me selecting [738_noise.simplex_529135023]({m.as}#aud5). These features were not manually composed and *emerged* from the simulated annealing system controlling the Fourses synth. 

## Reflecting On Issues Of Control and Intervention
Annealing Strategies was an artistically successful piece for me and fostered a compositional workflow where a significant amount of agency was given to the computer without having to sacrifice sophistication in the music. I endeavoured to achieve this in [Stitch/Strata]({m.ss}) but was often unsuccessful in my attempts to have the computer be responsible for increasingly abstract and complex musical aspects such as high-level form. The compositional blockages of that project resulted in me utilising a workflow based on manually arranging small computer generated phrases and gestures of descriptor-driven concatenative synthesis outputs. This required me to alternate between generating those phrases and gestures, auditioning them and returning to the generation stage in order to make sense of the material and undertake further decisions about how it would be used in composition. Taking control in this way involved, to a large degree, relying on my intuition (such as for ordering of samples at the macro-level), rather than accepting what the computer had generated. [Annealing Strategies]({m.as}) was entirely different to this, with both the high-level and low-level formal decision making emerging from the control of SA, and much of the detail in the surface of the music being resolved by the system automatically.

Giving away control and agency fundamentally altered my interaction with sound materials and the ways that I was able to influence the compositional result. Without a mechanism for interacting with the system while it ran my main influence on the computer was to alternate between listening to an output of the system and to modify the parameters or the system itself. Examples of this method of interaction and control included changing the hyperparameters of the simulated annealing process: cooling rate, starting temperature, learning rate as well as the random seed and type for the procedural noise graph. Instead of thinking about how I could achieve specific sonic moments, I was focused on creating a set of conditions in which a particular overarching musical behaviour would emerge. The system would then be responsible for creating detail and sophistication within the constraints of that process. This compositional workflow relates directly back to the notion of "lose control gain influence", discussed in ["Situating My Practice"]({m.ca}#situating-my-practice). By affording the computer the role of creating structure, I was able to achieve a coherency at many hierarchical levels of form without having to design specific musical moments or rely on modelling my intuitive and manual decision making. This took away the possibility of honing a specific musical section or idea that I can imagine or plan, but allowed the computer to produce surprising and unanticipated outcomes that challenge my compositional tendencies.

### Iterating On Approaches From Annealing Strategies
While there was a high degree of success in this approach it was not a generalisable workflow that I could apply to different materials or conceptual goals in the future. The combination of the Fourses synth, the simulated annealing algorithm and the single input interface came together almost serendipitously without having to explore a number of other strategies for achieving my goals. In a sense, I was fortunate that these technologies worked together and were well-suited to the aesthetic and conceptual aims of the piece. SA, which had a significant influence on the results produced by the system was suited to the specific conceptual and artistic aims of this project, but is not necessarily appropriate for all types of creative aims I will have in the future. Furthermore, the single input interface created a novel one-to-many mapping for the parameters of the Fourses synth but is not something I would use in every scenario where that issue of control arises.

Another aspect that makes it difficult to carry forward the successes of [Annealing Strategies]({m.as}) into future projects is the annealing algorithm. This algorithm has a scope of problems it solves well and these aligned well with my specific compositional problems. The confluence of these two things meant that I accepted and embraced the influencing properties of the algorithm into the work. For example, the convergent behaviour of simulated annealing produced results where in each iteration the Fourses synth begins by modifying the parameters wildly. As the algorithm performs its function, the scope of sounds it produces is reduced. This behaviour was compatible with the conceptual vision I had for the piece, and therefore much of the algorithm inflects the work as a result. I can imagine a scenario in the future where a more complex and non-linear formal structure is desired where simply running the algorithm will not be able to serve those aims well. 

Furthermore, there were moments in the creative process where I was not sure that the algorithm would be able to produce a satisfying piece in one iteration. I auditioned several good iterations with novel characteristics but none of them were convincing to me as standalone pieces. Prior to producing [738_noise.simplex_529135023]({m.as}#aud5), I anticipated that to achieve a satisfying solution I would have to edit and stitch together sections from multiple iterations which I deemed to be satisfying. To me, this would have made the use of SA feel somewhat arbitrary and pointless. If I had not incorporated the inherent behaviour of SA and let it influence the high and low-level form, then another algorithm for the same purpose that was built from the ground-up would likely controllable, customisable and required less blind experimentation to produce a desirable result. I wanted the algorithm to shape the piece entirely and with minimal intervention from me once running, and editing together numerous takes to achieve a structure that progresses from loud to quiet parameter combinations of the Fourses synth would have betrayed my initial conceptual aims.

The convergence of many aspects made Annealing Strategies successful but not a replicable workflow that could be iterated on in the future. After I had completed this project, I felt as if I had explored the semi-supervised and unsupervised range of the spectrum of computer agency. I was able to re-visit and potentially solve many issues I came across in [Stitch/Strata]({m.ss}), but it also raised new questions about how much immediacy and influence I would like to retain in future works. As such, I was motivated going forward to keep exploring the different balances of agency in my creative practice. The next project, [Refracted Touch]({m.rt}) investigates how real-time live electronics can be used as a way of structuring formal events through improvisation. In terms of the overall portfolio, it is quite experimental and divergent, perhaps demonstrating a last effort to explore widely before honing my compositional practice toward a more stable set of techniques and practices in [Reconstruction Error]({m.re}) and [{m.emname}]({m.em}).

## Related Links and Media
I gave a presentation at the <a href="http://electricspring.co.uk/electric-spring-2018/">2018 Electric Spring Creative Coding Lab Symposium</a> that discussed the motivations and creative process for Annealing Strategies. While this video at times skims over detail due to time constraints of the presentation it is documentation that supports this work and thus deserves inclusion in this thesis.

<YouTube 
url="https://www.youtube.com/embed/Ro30O9u7l8M"
figure="VIDEO 3"
caption='"Making Decisions About Making Decisions About Making Decisions" presentation given at the 2018 Electric Spring Creative Coding Lab Symposium.'
/>

<NextSection 
next="Refracted Touch"
link={m.rt}
/>

<style>
    h1 {counter-reset: h2}
    h2 {counter-reset: h3}
    h3 {counter-reset: h4}

    h1:before {content: "4.1." " "}

    h2:before {
        content: "4.1." counter(h2, decimal) " ";
        counter-increment: h2;
    }
    h3:before {
        content: "4.1." counter(h2, decimal) "." counter(h3, decimal) " ";
        counter-increment: h3;
    }

    h2.nocount:before, h3.nocount:before {
        content : "";
        counter-increment: none;
    }
</style>
    